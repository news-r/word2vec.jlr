---
title: "Clustering"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Clustering}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

You _must_ run `setup_word2vec` at the begining of every session, you will otherwise encounter errors and be prompted to do so.


You _must_ run `setup_word2vec` at the begining of every session, you will otherwise encounter errors and be prompted to do so.

```{r}
library(word2vec.r)

# setup word2vec Julia dependency
setup_word2vec()
```

The package comes with a dataset, [Macbeth by Shakespeare](https://en.wikipedia.org/wiki/Macbeth). However, being a corpus of 17,319 words it is not lazyly loaded and needs to be imported manually with the `data` function. Note that the dataset is mildly preprocessed, all words are lowercase and punctuation has been removed.

```{r}
data("macbeth", package = "word2vec.r")
```

## Functions

You can also cluster words.

```{r}
model_path <- word2clusters(macbeth, classes = 50L) # train model
model <- word_clusters(model_path)
```

We provide both a functional API and a reference class.

- `vocabulary`
- `in_vocabulary`
- `index`
- `get_cluster`
- `clusters`
- `get_words`

## Functional

```{r}
get_cluster(model, "king")
get_cluster(model, "macbeth")
```

## Reference Class

We provide a reference class, because it is tedious to specify the vectors (`model` object in this example) as first argument to every functionv.

```{r}
wc <- WordClusters$new(model)
wc$get_words(4L)
wc$clusters()
```
