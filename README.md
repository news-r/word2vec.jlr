
<!-- README.md is generated from README.Rmd. Please edit that file -->

# word2vec.r

<!-- badges: start -->

[![Travis build
status](https://travis-ci.org/news-r/word2vec.r.svg?branch=master)](https://travis-ci.org/news-r/word2vec.r)
<!-- badges: end -->

`word2vec.r` is an R wrapper to the `Word2Vec.jl` Julia package.

## Installation

Being a wrapper to a [Julia](https://julialang.org/) package,
`word2vec.r` requires the latter to be installed.

You can install the package from Github with:

``` r
# install.packages("remotes")
remotes::install_github("news-r/word2vec.r")
```

## Example

You *must* run `setup_word2vec` at the begining of every session, you
will otherwise encounter errors and be prompted to do so.

``` r
library(word2vec.r)

# setup word2vec Julia dependency
setup_word2vec()
#> Julia version 1.1.1 at location /Applications/Julia-1.1.app/Contents/Resources/julia/bin will be used.
#> Loading setup script for JuliaCall...
#> Finish loading setup script for JuliaCall.
```

The package comes with a dataset, [Macbeth by
Shakespeare](https://en.wikipedia.org/wiki/Macbeth). However, being a
corpus of 17,319 words it is not lazyly loaded and needs to be imported
manually with the `data` function.

``` r
# sample corpus
data("macbeth", package = "word2vec.r")
```

With data we can train a model and extract the vectors.

``` r
# train model
model_path <- word2vec(macbeth)
#> word2vec("/var/folders/n9/ys9t1h091jq80g4hww24v8g0n7v578/T//Rtmp0PLPuD/file48f273af76fd", "/var/folders/n9/ys9t1h091jq80g4hww24v8g0n7v578/T//Rtmp0PLPuD/file48f25d761642.txt", size = 100, window = 5, 
#> sample = 0.001, hs = 0,  negative = 5, 
#> threads = 12, iter = 5, min_count = 5, 
#> alpha = 0.025, debug = 2, binary = 0, cbow = 1, 
#> verbose = true)

# get word vectors
model <- word_vectors(model_path)
```

There are then a multitude of functions one can use on the model.

  - `get_vector`
  - `vocabulary`
  - `in_vocabulary`
  - `size`
  - `index`
  - `cosine`
  - `cosine_similar_words`
  - `similarity`
  - `analogy`
  - `analogy_words`

All are well documented and have examples, visit their respective man
pages with i.e.: `?get_vector`. Note that since all the functions listed
above require the output of `word_vectors` (the `model` object in our
case). Therefore a convenient reference class also exists.

### Functional

``` r
#Â words similar to king
cosine_similar_words(model, "king", 5L)
#> [1] "king"  "rosse" "me"    "macd"  "thy"

# size of model
size(model)
#> # A tibble: 1 x 2
#>   length words
#>    <int> <int>
#> 1    100   511
```

### Reference Class

``` r
wv <- WordVectors$new(model)
wv$get_vector("macbeth")
#>   [1] -0.003259485 -0.082122283  0.058061465 -0.183721967  0.086732987
#>   [6] -0.022230180  0.035372097 -0.036849405 -0.071784896  0.210477694
#>  [11]  0.099944065  0.168955011 -0.163269261 -0.153090426 -0.002574467
#>  [16]  0.162199389  0.081916213  0.075789152  0.112488003  0.085189812
#>  [21]  0.023189018  0.071407571  0.067928372 -0.212084853 -0.053798917
#>  [26] -0.101635911  0.001152676  0.019518333  0.160006482  0.095863122
#>  [31] -0.084426223 -0.031267159 -0.215506654  0.069233954 -0.104877048
#>  [36] -0.012343043  0.111781342 -0.083936454  0.094831359 -0.043700534
#>  [41] -0.065950474  0.155544920 -0.098292210 -0.102924085  0.106460213
#>  [46]  0.115002248 -0.054061445 -0.014673801 -0.053667182 -0.081023712
#>  [51]  0.022718067 -0.076389014  0.041087488  0.004069652 -0.068130678
#>  [56] -0.056737535  0.109879191 -0.064013508  0.008367957 -0.180972482
#>  [61]  0.059267776 -0.062437400 -0.017862243 -0.054811860 -0.083251905
#>  [66]  0.111215825  0.053070614 -0.099845264  0.164035673  0.062070426
#>  [71]  0.022034930  0.013898920  0.120667768 -0.106734503 -0.177542683
#>  [76] -0.022586333 -0.126031240 -0.036666388 -0.188190586 -0.123543812
#>  [81]  0.036679091  0.023502358  0.017316957 -0.115925329  0.048729024
#>  [86]  0.118494621 -0.021206415 -0.047440850  0.245224523 -0.050809487
#>  [91] -0.001387446  0.146639675 -0.022432486  0.051305843  0.039116177
#>  [96]  0.157307809  0.046250536  0.156757818  0.038538898 -0.128775079
wv$cosine("rosse")
#> # A tibble: 10 x 2
#>    index cosine
#>    <int>  <dbl>
#>  1    67  1    
#>  2    56  1.000
#>  3    50  1.000
#>  4    48  1.000
#>  5    89  1.000
#>  6   134  1.000
#>  7    17  1.000
#>  8     4  1.000
#>  9   106  1.000
#> 10    26  1.000
```
